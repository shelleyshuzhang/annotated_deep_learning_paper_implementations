{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StyleGAN-exp.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPClf+w3eB8agcBO6ihb/wp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtdGRmFJA873","executionInfo":{"status":"ok","timestamp":1632986776534,"user_tz":-480,"elapsed":25225,"user":{"displayName":"Shu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13614762352245473110"}},"outputId":"1daf8d04-345e-4c6f-db43-e42b55cf8032"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9V8BVqvBx_S","executionInfo":{"status":"ok","timestamp":1632986783622,"user_tz":-480,"elapsed":1243,"user":{"displayName":"Shu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13614762352245473110"}},"outputId":"67968a57-7a30-4a8e-875d-f23c7509aa96"},"source":["import os\n","path = \"/content/drive/MyDrive/Colab Notebooks/\" \\\n","       \"annotated_deep_learning_paper_implementations-master/\" \\\n","       \"labml_nn/gan/stylegan\"\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['__init__.py', 'readme.md', 'experiment.py', 'StyleGAN-exp.ipynb']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"ymxJOIKxKbPH","executionInfo":{"status":"ok","timestamp":1632986791704,"user_tz":-480,"elapsed":657,"user":{"displayName":"Shu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13614762352245473110"}}},"source":["import math\n","import os\n","import hashlib\n","from urllib.request import urlretrieve\n","import zipfile\n","import gzip\n","import shutil\n","\n","import numpy as np\n","from PIL import Image\n","from tqdm import tqdm\n","\n","\n","def _read32(bytestream):\n","    \"\"\"\n","    Read 32-bit integer from bytesteam\n","    :param bytestream: A bytestream\n","    :return: 32-bit integer\n","    \"\"\"\n","    dt = np.dtype(np.uint32).newbyteorder('>')\n","    return np.frombuffer(bytestream.read(4), dtype=dt)[0]\n","\n","\n","def _unzip(save_path, _, database_name, data_path):\n","    \"\"\"\n","    Unzip wrapper with the same interface as _ungzip\n","    :param save_path: The path of the gzip files\n","    :param database_name: Name of database\n","    :param data_path: Path to extract to\n","    :param _: HACK - Used to have to same interface as _ungzip\n","    \"\"\"\n","    print('Extracting {}...'.format(database_name))\n","    with zipfile.ZipFile(save_path) as zf:\n","        zf.extractall(data_path)\n","\n","\n","def _ungzip(save_path, extract_path, database_name, _):\n","    \"\"\"\n","    Unzip a gzip file and extract it to extract_path\n","    :param save_path: The path of the gzip files\n","    :param extract_path: The location to extract the data to\n","    :param database_name: Name of database\n","    :param _: HACK - Used to have to same interface as _unzip\n","    \"\"\"\n","    # Get data from save_path\n","    with open(save_path, 'rb') as f:\n","        with gzip.GzipFile(fileobj=f) as bytestream:\n","            magic = _read32(bytestream)\n","            if magic != 2051:\n","                raise ValueError('Invalid magic number {} in file: {}'.format(magic, f.name))\n","            num_images = _read32(bytestream)\n","            rows = _read32(bytestream)\n","            cols = _read32(bytestream)\n","            buf = bytestream.read(rows * cols * num_images)\n","            data = np.frombuffer(buf, dtype=np.uint8)\n","            data = data.reshape(num_images, rows, cols)\n","\n","    # Save data to extract_path\n","    for image_i, image in enumerate(\n","            tqdm(data, unit='File', unit_scale=True, miniters=1, desc='Extracting {}'.format(database_name))):\n","        Image.fromarray(image, 'L').save(os.path.join(extract_path, 'image_{}.jpg'.format(image_i)))\n","\n","\n","def get_image(image_path, width, height, mode):\n","    \"\"\"\n","    Read image from image_path\n","    :param image_path: Path of image\n","    :param width: Width of image\n","    :param height: Height of image\n","    :param mode: Mode of image\n","    :return: Image data\n","    \"\"\"\n","    image = Image.open(image_path)\n","\n","    if image.size != (width, height):  # HACK - Check if image is from the CELEBA dataset\n","        # Remove most pixels that aren't part of a face\n","        face_width = face_height = 108\n","        j = (image.size[0] - face_width) // 2\n","        i = (image.size[1] - face_height) // 2\n","        image = image.crop([j, i, j + face_width, i + face_height])\n","        image = image.resize([width, height], Image.BILINEAR)\n","\n","    return np.array(image.convert(mode))\n","\n","\n","def get_batch(image_files, width, height, mode):\n","    data_batch = np.array(\n","        [get_image(sample_file, width, height, mode) for sample_file in image_files]).astype(np.float32)\n","\n","    # Make sure the images are in 4 dimensions\n","    if len(data_batch.shape) < 4:\n","        data_batch = data_batch.reshape(data_batch.shape + (1,))\n","\n","    return data_batch\n","\n","\n","def images_square_grid(images, mode):\n","    \"\"\"\n","    Save images as a square grid\n","    :param images: Images to be used for the grid\n","    :param mode: The mode to use for images\n","    :return: Image of images in a square grid\n","    \"\"\"\n","    # Get maximum size for square grid of images\n","    save_size = math.floor(np.sqrt(images.shape[0]))\n","\n","    # Scale to 0-255\n","    images = (((images - images.min()) * 255) / (images.max() - images.min())).astype(np.uint8)\n","\n","    # Put images in a square arrangement\n","    images_in_square = np.reshape(\n","            images[:save_size*save_size],\n","            (save_size, save_size, images.shape[1], images.shape[2], images.shape[3]))\n","    if mode == 'L':\n","        images_in_square = np.squeeze(images_in_square, 4)\n","\n","    # Combine images to grid image\n","    new_im = Image.new(mode, (images.shape[1] * save_size, images.shape[2] * save_size))\n","    for col_i, col_images in enumerate(images_in_square):\n","        for image_i, image in enumerate(col_images):\n","            im = Image.fromarray(image, mode)\n","            new_im.paste(im, (col_i * images.shape[1], image_i * images.shape[2]))\n","\n","    return new_im\n","\n","\n","def download_extract(database_name, data_path):\n","    \"\"\"\n","    Download and extract database\n","    :param database_name: Database name\n","    \"\"\"\n","    DATASET_CELEBA_NAME = 'celeba'\n","    DATASET_MNIST_NAME = 'mnist'\n","\n","    if database_name == DATASET_CELEBA_NAME:\n","        url = 'https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip'\n","        hash_code = '00d2c5bc6d35e252742224ab0c1e8fcb'\n","        extract_path = os.path.join(data_path, 'img_align_celeba')\n","        save_path = os.path.join(data_path, 'celeba.zip')\n","        extract_fn = _unzip\n","  \n","    if os.path.exists(extract_path):\n","        print('Found {} Data'.format(database_name))\n","        return\n","\n","    if not os.path.exists(data_path):\n","        os.makedirs(data_path)\n","\n","    if not os.path.exists(save_path):\n","        with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Downloading {}'.format(database_name)) as pbar:\n","            urlretrieve(\n","                url,\n","                save_path,\n","                pbar.hook)\n","\n","    assert hashlib.md5(open(save_path, 'rb').read()).hexdigest() == hash_code, \\\n","        '{} file is corrupted.  Remove the file and try again.'.format(save_path)\n","\n","    os.makedirs(extract_path)\n","    try:\n","        extract_fn(save_path, extract_path, database_name, data_path)\n","    except Exception as err:\n","        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\n","        raise err\n","\n","    # Remove compressed data\n","    os.remove(save_path)\n","\n","\n","class Dataset(object):\n","    \"\"\"\n","    Dataset\n","    \"\"\"\n","    def __init__(self, dataset_name, data_files):\n","        \"\"\"\n","        Initalize the class\n","        :param dataset_name: Database name\n","        :param data_files: List of files in the database\n","        \"\"\"\n","        DATASET_CELEBA_NAME = 'celeba'\n","        DATASET_MNIST_NAME = 'mnist'\n","        IMAGE_WIDTH = 28\n","        IMAGE_HEIGHT = 28\n","\n","        if dataset_name == DATASET_CELEBA_NAME:\n","            self.image_mode = 'RGB'\n","            image_channels = 3\n","\n","        elif dataset_name == DATASET_MNIST_NAME:\n","            self.image_mode = 'L'\n","            image_channels = 1\n","\n","        self.data_files = data_files\n","        self.shape = len(data_files), IMAGE_WIDTH, IMAGE_HEIGHT, image_channels\n","\n","    def get_batches(self, batch_size):\n","        \"\"\"\n","        Generate batches\n","        :param batch_size: Batch Size\n","        :return: Batches of data\n","        \"\"\"\n","        IMAGE_MAX_VALUE = 255\n","\n","        current_index = 0\n","        while current_index + batch_size <= self.shape[0]:\n","            data_batch = get_batch(\n","                self.data_files[current_index:current_index + batch_size],\n","                *self.shape[1:3],\n","                self.image_mode)\n","\n","            current_index += batch_size\n","\n","            yield data_batch / IMAGE_MAX_VALUE - 0.5\n","\n","\n","class DLProgress(tqdm):\n","    \"\"\"\n","    Handle Progress Bar while Downloading\n","    \"\"\"\n","    last_block = 0\n","\n","    def hook(self, block_num=1, block_size=1, total_size=None):\n","        \"\"\"\n","        A hook function that will be called once on establishment of the network connection and\n","        once after each block read thereafter.\n","        :param block_num: A count of blocks transferred so far\n","        :param block_size: Block size in bytes\n","        :param total_size: The total size of the file. This may be -1 on older FTP servers which do not return\n","                            a file size in response to a retrieval request.\n","        \"\"\"\n","        self.total = total_size\n","        self.update((block_num - self.last_block) * block_size)\n","        self.last_block = block_num"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuilcLdZKiJB","executionInfo":{"status":"ok","timestamp":1632986805193,"user_tz":-480,"elapsed":492,"user":{"displayName":"Shu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13614762352245473110"}},"outputId":"69ad0039-4731-4566-dda4-e21b1ebb88ce"},"source":["download_extract('celeba', \n","                 '/content/drive/My Drive/Colab Notebooks/annotated_deep_learning_paper_implementations-master/data/stylegan2')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found celeba Data\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0S3AY-89ESk0","executionInfo":{"status":"ok","timestamp":1632986813173,"user_tz":-480,"elapsed":5806,"user":{"displayName":"Shu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13614762352245473110"}},"outputId":"096025ae-398f-4041-d811-59658f36b016"},"source":["!pip install labml-nn"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting labml-nn\n","  Downloading labml_nn-0.4.114-py3-none-any.whl (290 kB)\n","\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 40 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 61 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 290 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from labml-nn) (1.9.0+cu102)\n","Collecting labml>=0.4.133\n","  Downloading labml-0.4.134-py3-none-any.whl (121 kB)\n","\u001b[K     |████████████████████████████████| 121 kB 41.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from labml-nn) (1.19.5)\n","Collecting einops\n","  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n","Collecting labml-helpers>=0.4.84\n","  Downloading labml_helpers-0.4.84-py3-none-any.whl (18 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from labml>=0.4.133->labml-nn) (3.13)\n","Collecting gitpython\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 44.5 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython->labml>=0.4.133->labml-nn) (3.7.4.3)\n","Collecting smmap<5,>=3.0.1\n","  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, gitdb, gitpython, labml, labml-helpers, einops, labml-nn\n","Successfully installed einops-0.3.2 gitdb-4.0.7 gitpython-3.1.24 labml-0.4.134 labml-helpers-0.4.84 labml-nn-0.4.114 smmap-4.0.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZ5ju3D0E1Np","executionInfo":{"status":"ok","timestamp":1632986957771,"user_tz":-480,"elapsed":125356,"user":{"displayName":"Shu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13614762352245473110"}},"outputId":"02cbff63-da6c-474c-a39a-77b87fb9b3b3"},"source":["!python experiment.py"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/annotated_deep_learning_paper_implementations-master/data/stylegan2/img_align_celeba\n","\r\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mNot a valid git repository: \u001b[1m/content/drive/My Drive/Colab Notebooks/annotated_deep_learning_paper_implementations-master\u001b[0m\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\r\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Prepare device...\n","  Prepare device_info\u001b[32m...[DONE]\u001b[0m\u001b[34m\t63.23ms\u001b[0m\n","Prepare device\u001b[32m...[DONE]\u001b[0m\u001b[34m\t63.68ms\u001b[0m\n","\n","\u001b[1m\u001b[4mstylegan2\u001b[0m: \u001b[34md6e336fe21bf11ec95820242ac1c0002\u001b[0m\n","\t[dirty]: \u001b[1m\u001b[33m\"\"\u001b[0m\n","\u001b[1m~/labml/configs.yaml\u001b[0m does not exist. Creating \u001b[34m/root/.labml/configs.yaml\u001b[0m\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (0)...\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (1)...\u001b[0m\n","loss.discriminator: tensor(4.3809, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       0:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 7,173ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m  0ms  \u001b[0m  \u001b[34m7,173ms\u001b[0m\u001b[35m  0:00m/298:51m  \u001b[0mloss.generator: tensor(4.7699, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m       1:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 7,173ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 887ms  \u001b[0m loss.discriminator: \u001b[1m 4.38094\u001b[0m loss.generator: \u001b[1m 4.76992\u001b[0m  \u001b[34m16,931ms\u001b[0m\u001b[35m  0:00m/705:27m  \u001b[0mloss.discriminator: tensor(5.7671, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       1:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 3,968ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 887ms  \u001b[0m loss.discriminator: \u001b[1m 4.38094\u001b[0m loss.generator: \u001b[1m 4.76992\u001b[0m  \u001b[34m16,931ms\u001b[0m\u001b[35m  0:00m/705:27m  \u001b[0mloss.generator: tensor(-3.2946, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m       2:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 3,968ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 840ms  \u001b[0m loss.discriminator: \u001b[1m 5.76706\u001b[0m loss.generator: \u001b[1m-3.294610\u001b[0m  \u001b[34m7,430ms\u001b[0m\u001b[35m  0:00m/309:34m  \u001b[0mloss.discriminator: tensor(4.4728, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       2:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 2,564ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 840ms  \u001b[0m loss.discriminator: \u001b[1m 5.76706\u001b[0m loss.generator: \u001b[1m-3.294610\u001b[0m  \u001b[34m7,430ms\u001b[0m\u001b[35m  0:00m/309:34m  \u001b[0mloss.generator: tensor(4.3604, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (2)...\u001b[0m\n","loss.discriminator: tensor(5.4536, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       3:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 3,992ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 830ms  \u001b[0m loss.discriminator: \u001b[1m 4.47281\u001b[0m loss.generator: \u001b[1m 4.36043\u001b[0m  \u001b[34m4,530ms\u001b[0m\u001b[35m  0:00m/188:44m  \u001b[0mloss.generator: tensor(-3.3189, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m       4:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 3,992ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 809ms  \u001b[0m loss.discriminator: \u001b[1m 5.45358\u001b[0m loss.generator: \u001b[1m-3.318914\u001b[0m loss.gp: \u001b[1m0.000210\u001b[0m  \u001b[34m5,514ms\u001b[0m\u001b[35m  0:00m/229:44m  \u001b[0mloss.discriminator: tensor(4.4751, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       4:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 2,679ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 809ms  \u001b[0m loss.discriminator: \u001b[1m 5.45358\u001b[0m loss.generator: \u001b[1m-3.318914\u001b[0m loss.gp: \u001b[1m0.000210\u001b[0m  \u001b[34m5,514ms\u001b[0m\u001b[35m  0:00m/229:44m  \u001b[0mloss.generator: tensor(4.1525, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m       5:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 2,679ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 797ms  \u001b[0m loss.discriminator: \u001b[1m 4.47514\u001b[0m loss.generator: \u001b[1m 4.15245\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000210\u001b[0m  \u001b[34m3,842ms\u001b[0m\u001b[35m  0:00m/160:03m  \u001b[0mloss.discriminator: tensor(5.1830, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       5:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 1,933ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 797ms  \u001b[0m loss.discriminator: \u001b[1m 4.47514\u001b[0m loss.generator: \u001b[1m 4.15245\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000210\u001b[0m  \u001b[34m3,842ms\u001b[0m\u001b[35m  0:00m/160:03m  \u001b[0mloss.generator: tensor(-3.2424, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m       6:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 1,933ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 789ms  \u001b[0m loss.discriminator: \u001b[1m 5.18302\u001b[0m loss.generator: \u001b[1m-3.242352\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000210\u001b[0m  \u001b[34m3,023ms\u001b[0m\u001b[35m  0:00m/125:56m  \u001b[0mloss.discriminator: tensor(4.3643, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (3)...\u001b[0m\n","loss.generator: tensor(3.9564, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m       7:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 1,496ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 4.36429\u001b[0m loss.generator: \u001b[1m 3.95642\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000210\u001b[0m  \u001b[34m2,459ms\u001b[0m\u001b[35m  0:00m/102:26m  \u001b[0mloss.discriminator: tensor(4.9702, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       7:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 3,108ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 4.36429\u001b[0m loss.generator: \u001b[1m 3.95642\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000210\u001b[0m  \u001b[34m2,459ms\u001b[0m\u001b[35m  0:00m/102:26m  \u001b[0mloss.generator: tensor(-3.2127, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m       8:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 3,108ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 784ms  \u001b[0m loss.discriminator: \u001b[1m 4.97017\u001b[0m loss.generator: \u001b[1m-3.212693\u001b[0m loss.gp: \u001b[1m0.000173\u001b[0m  \u001b[34m4,014ms\u001b[0m\u001b[35m  0:00m/167:15m  \u001b[0mloss.discriminator: tensor(4.3476, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       8:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 2,202ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 784ms  \u001b[0m loss.discriminator: \u001b[1m 4.97017\u001b[0m loss.generator: \u001b[1m-3.212693\u001b[0m loss.gp: \u001b[1m0.000173\u001b[0m  \u001b[34m4,014ms\u001b[0m\u001b[35m  0:00m/167:15m  \u001b[0mloss.generator: tensor(3.7380, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m       9:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 2,202ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 784ms  \u001b[0m loss.discriminator: \u001b[1m 4.34764\u001b[0m loss.generator: \u001b[1m3.737997\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000173\u001b[0m  \u001b[34m3,061ms\u001b[0m\u001b[35m  0:00m/127:31m  \u001b[0mloss.discriminator: tensor(4.7729, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m       9:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 1,663ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 784ms  \u001b[0m loss.discriminator: \u001b[1m 4.34764\u001b[0m loss.generator: \u001b[1m3.737997\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000173\u001b[0m  \u001b[34m3,061ms\u001b[0m\u001b[35m  0:00m/127:31m  \u001b[0mloss.generator: tensor(-3.1592, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (4)...\u001b[0m\n","loss.discriminator: tensor(4.2233, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      10:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 1,343ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 4.77288\u001b[0m loss.generator: \u001b[1m-3.159213\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000173\u001b[0m  \u001b[34m2,502ms\u001b[0m\u001b[35m  0:00m/104:13m  \u001b[0mloss.generator: tensor(3.6673, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m      11:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 1,343ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 4.22334\u001b[0m loss.generator: \u001b[1m3.667309\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000173\u001b[0m  \u001b[34m2,166ms\u001b[0m\u001b[35m  0:00m/ 90:13m  \u001b[0mloss.discriminator: tensor(4.6107, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      11:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 3,128ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 4.22334\u001b[0m loss.generator: \u001b[1m3.667309\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000173\u001b[0m  \u001b[34m2,166ms\u001b[0m\u001b[35m  0:00m/ 90:13m  \u001b[0mloss.generator: tensor(-3.0318, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m      12:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 3,128ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 783ms  \u001b[0m loss.discriminator: \u001b[1m 4.61070\u001b[0m loss.generator: \u001b[1m-3.031811\u001b[0m loss.gp: \u001b[1m0.000146\u001b[0m  \u001b[34m3,944ms\u001b[0m\u001b[35m  0:00m/164:19m  \u001b[0mloss.discriminator: tensor(4.1144, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      12:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 2,223ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 783ms  \u001b[0m loss.discriminator: \u001b[1m 4.61070\u001b[0m loss.generator: \u001b[1m-3.031811\u001b[0m loss.gp: \u001b[1m0.000146\u001b[0m  \u001b[34m3,944ms\u001b[0m\u001b[35m  0:00m/164:19m  \u001b[0mloss.generator: tensor(3.5572, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (5)...\u001b[0m\n","loss.discriminator: tensor(4.4352, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      13:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 1,678ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 782ms  \u001b[0m loss.discriminator: \u001b[1m 4.11440\u001b[0m loss.generator: \u001b[1m3.557203\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000146\u001b[0m  \u001b[34m3,030ms\u001b[0m\u001b[35m  0:00m/126:13m  \u001b[0mloss.generator: tensor(-2.9693, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m      14:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 1,678ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 782ms  \u001b[0m loss.discriminator: \u001b[1m 4.43517\u001b[0m loss.generator: \u001b[1m-2.969313\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000146\u001b[0m  \u001b[34m2,481ms\u001b[0m\u001b[35m  0:00m/103:21m  \u001b[0mloss.discriminator: tensor(4.0712, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      14:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 1,356ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 782ms  \u001b[0m loss.discriminator: \u001b[1m 4.43517\u001b[0m loss.generator: \u001b[1m-2.969313\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000146\u001b[0m  \u001b[34m2,481ms\u001b[0m\u001b[35m  0:00m/103:21m  \u001b[0mloss.generator: tensor(3.4517, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m      15:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 1,356ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 784ms  \u001b[0m loss.discriminator: \u001b[1m 4.07117\u001b[0m loss.generator: \u001b[1m3.451675\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000146\u001b[0m  \u001b[34m2,160ms\u001b[0m\u001b[35m  0:00m/ 89:59m  \u001b[0mloss.discriminator: tensor(4.3020, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      15:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 3,127ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 784ms  \u001b[0m loss.discriminator: \u001b[1m 4.07117\u001b[0m loss.generator: \u001b[1m3.451675\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000146\u001b[0m  \u001b[34m2,160ms\u001b[0m\u001b[35m  0:01m/ 89:59m  \u001b[0mloss.generator: tensor(-2.8906, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (6)...\u001b[0m\n","loss.discriminator: tensor(3.9561, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      16:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 2,223ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 782ms  \u001b[0m loss.discriminator: \u001b[1m 4.30199\u001b[0m loss.generator: \u001b[1m-2.890645\u001b[0m loss.gp: \u001b[1m0.000127\u001b[0m  \u001b[34m3,927ms\u001b[0m\u001b[35m  0:01m/163:37m  \u001b[0mloss.generator: tensor(3.3123, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m      17:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 2,223ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 3.95607\u001b[0m loss.generator: \u001b[1m3.312263\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000127\u001b[0m  \u001b[34m3,028ms\u001b[0m\u001b[35m  0:01m/126:08m  \u001b[0mloss.discriminator: tensor(4.1678, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      17:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 1,678ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 3.95607\u001b[0m loss.generator: \u001b[1m3.312263\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000127\u001b[0m  \u001b[34m3,028ms\u001b[0m\u001b[35m  0:01m/126:08m  \u001b[0mloss.generator: tensor(-2.8097, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m      18:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 1,678ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 786ms  \u001b[0m loss.discriminator: \u001b[1m 4.16777\u001b[0m loss.generator: \u001b[1m-2.809694\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000127\u001b[0m  \u001b[34m2,482ms\u001b[0m\u001b[35m  0:01m/103:24m  \u001b[0mloss.discriminator: tensor(3.8597, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      18:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 1,352ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 786ms  \u001b[0m loss.discriminator: \u001b[1m 4.16777\u001b[0m loss.generator: \u001b[1m-2.809694\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000127\u001b[0m  \u001b[34m2,482ms\u001b[0m\u001b[35m  0:01m/103:24m  \u001b[0mloss.generator: tensor(3.2131, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (7)...\u001b[0m\n","loss.discriminator: tensor(4.0567, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      19:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 3,122ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 787ms  \u001b[0m loss.discriminator: \u001b[1m 3.85968\u001b[0m loss.generator: \u001b[1m3.213057\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000127\u001b[0m  \u001b[34m2,156ms\u001b[0m\u001b[35m  0:01m/ 89:47m  \u001b[0mloss.generator: tensor(-2.7277, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m      20:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 3,122ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 4.05670\u001b[0m loss.generator: \u001b[1m-2.727675\u001b[0m loss.gp: \u001b[1m0.000107\u001b[0m  \u001b[34m3,923ms\u001b[0m\u001b[35m  0:01m/163:27m  \u001b[0mloss.discriminator: tensor(3.7647, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33m      20:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 2,219ms  \u001b[0mGenerator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 785ms  \u001b[0m loss.discriminator: \u001b[1m 4.05670\u001b[0m loss.generator: \u001b[1m-2.727675\u001b[0m loss.gp: \u001b[1m0.000107\u001b[0m  \u001b[34m3,923ms\u001b[0m\u001b[35m  0:01m/163:27m  \u001b[0mloss.generator: tensor(3.1253, device='cuda:0', grad_fn=<NegBackward>)\n","\u001b[1m\u001b[33m      21:  \u001b[0mDiscriminator:\u001b[2m\u001b[37m  ...\u001b[0m\u001b[34m 2,219ms  \u001b[0mGenerator:\u001b[2m\u001b[37m 100%\u001b[0m\u001b[34m 784ms  \u001b[0m loss.discriminator: \u001b[1m 3.76468\u001b[0m loss.generator: \u001b[1m3.125252\u001b[0m loss.gp: \u001b[2m\u001b[37m0.000107\u001b[0m  \u001b[34m3,020ms\u001b[0m\u001b[35m  0:01m/125:49m  \u001b[0mloss.discriminator: tensor(3.9477, device='cuda:0', grad_fn=<AddBackward0>)\n","\u001b[1m\u001b[33mStill updating app.labml.ai, please wait for it to complete...\u001b[0m\n","Traceback (most recent call last):\n","  File \"experiment.py\", line 480, in <module>\n","    main()\n","  File \"experiment.py\", line 476, in main\n","    configs.train()\n","  File \"experiment.py\", line 440, in train\n","    self.step(i)\n","  File \"experiment.py\", line 400, in step\n","    tracker.add('loss.generator', gen_loss)\n","  File \"/usr/local/lib/python3.7/dist-packages/labml/tracker.py\", line 236, in add\n","    _internal().store(args[0], args[1])\n","  File \"/usr/local/lib/python3.7/dist-packages/labml/internal/tracker/__init__.py\", line 167, in store\n","    self.indicators[key].collect_value(value)\n","  File \"/usr/local/lib/python3.7/dist-packages/labml/internal/tracker/indicators/numeric.py\", line 81, in collect_value\n","    value = to_numpy(value).ravel()\n","  File \"/usr/local/lib/python3.7/dist-packages/labml/internal/util/values.py\", line 23, in to_numpy\n","    return value.data.cpu().numpy()\n","KeyboardInterrupt\n","\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\u001b[33m\u001b[1m\u001b[4m\n","LABML WARNING\n","\u001b[0mFailed to send to https://api.labml.ai/api/v1/track?run_uuid=d6e336fe21bf11ec95820242ac1c0002&labml_version=0.4.134: \u001b[1m502\u001b[0m\n","Bad Gateway\u001b[2m\u001b[37m\n","--------------------------------------------------\u001b[0m\n","\u001b[1m\u001b[33mRetrying again in 10 seconds (8)...\u001b[0m\n","Exception ignored in: <module 'threading' from '/usr/lib/python3.7/threading.py'>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 1307, in _shutdown\n","^C\n"]}]}]}